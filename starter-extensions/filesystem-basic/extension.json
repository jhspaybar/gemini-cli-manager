{
  "id": "filesystem-basic",
  "name": "Filesystem Operations",
  "version": "1.0.0",
  "description": "Safe filesystem operations with security-focused patterns and best practices",
  "mcp_servers": {
    "fs-server": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-filesystem", "/tmp"],
      "cwd": ".",
      "timeout": 10000
    }
  },
  "context_file_name": "FILESYSTEM.md",
  "context_content": "# FILESYSTEM.md - Safe Filesystem Operations Guide\n\nThis guide provides safe patterns and best practices for filesystem operations. Always prioritize security and data integrity when working with files and directories.\n\n## Core Principles\n\n1. **Always validate paths** - Never trust user input\n2. **Check permissions** - Ensure proper access rights\n3. **Handle errors gracefully** - Filesystem operations can fail\n4. **Use atomic operations** - Prevent data corruption\n5. **Clean up resources** - Close files and remove temporary files\n\n## Safe Path Handling\n\n### Path Validation\n\n```bash\n# Always resolve paths to prevent traversal attacks\nrealpath \"$user_path\" || exit 1\n\n# Check if path is within allowed directory\nallowed_dir=\"/home/user/workspace\"\nresolved_path=$(realpath \"$user_path\")\nif [[ ! \"$resolved_path\" =~ ^\"$allowed_dir\" ]]; then\n    echo \"Error: Path outside allowed directory\"\n    exit 1\nfi\n```\n\n### Path Sanitization\n\n```python\nimport os\nfrom pathlib import Path\n\ndef safe_join(base_path, user_path):\n    \"\"\"Safely join paths preventing directory traversal\"\"\"\n    base = Path(base_path).resolve()\n    target = (base / user_path).resolve()\n    \n    # Ensure target is within base directory\n    if not str(target).startswith(str(base)):\n        raise ValueError(\"Path traversal attempt detected\")\n    \n    return target\n```\n\n## File Operations\n\n### Reading Files Safely\n\n```python\ndef read_file_safely(filepath, max_size=10*1024*1024):  # 10MB limit\n    \"\"\"Read file with size limit to prevent memory exhaustion\"\"\"\n    filepath = Path(filepath).resolve()\n    \n    # Check file exists and is a regular file\n    if not filepath.is_file():\n        raise ValueError(f\"Not a regular file: {filepath}\")\n    \n    # Check file size\n    size = filepath.stat().st_size\n    if size > max_size:\n        raise ValueError(f\"File too large: {size} bytes\")\n    \n    # Read with encoding error handling\n    try:\n        return filepath.read_text(encoding='utf-8', errors='replace')\n    except Exception as e:\n        raise IOError(f\"Failed to read file: {e}\")\n```\n\n### Writing Files Atomically\n\n```python\nimport tempfile\nimport shutil\n\ndef write_file_atomically(filepath, content):\n    \"\"\"Write file atomically to prevent corruption\"\"\"\n    filepath = Path(filepath).resolve()\n    \n    # Create temporary file in same directory\n    temp_fd, temp_path = tempfile.mkstemp(\n        dir=filepath.parent,\n        prefix=f\".{filepath.name}.\",\n        suffix=\".tmp\"\n    )\n    \n    try:\n        # Write to temporary file\n        with os.fdopen(temp_fd, 'w', encoding='utf-8') as f:\n            f.write(content)\n            f.flush()\n            os.fsync(f.fileno())  # Force write to disk\n        \n        # Set proper permissions\n        os.chmod(temp_path, 0o644)\n        \n        # Atomic rename\n        shutil.move(temp_path, filepath)\n    except Exception:\n        # Clean up on error\n        try:\n            os.unlink(temp_path)\n        except:\n            pass\n        raise\n```\n\n### Creating Directories Safely\n\n```python\ndef create_directory_safely(dirpath, mode=0o755):\n    \"\"\"Create directory with proper permissions\"\"\"\n    dirpath = Path(dirpath).resolve()\n    \n    try:\n        # Create with parents, exist_ok for idempotency\n        dirpath.mkdir(parents=True, exist_ok=True, mode=mode)\n        \n        # Verify permissions\n        actual_mode = dirpath.stat().st_mode & 0o777\n        if actual_mode != mode:\n            dirpath.chmod(mode)\n    except Exception as e:\n        raise IOError(f\"Failed to create directory: {e}\")\n```\n\n## Working with Temporary Files\n\n### Secure Temporary Files\n\n```python\nimport tempfile\nimport contextlib\n\n@contextlib.contextmanager\ndef secure_temp_file(suffix=None, prefix=None):\n    \"\"\"Create secure temporary file that's automatically cleaned up\"\"\"\n    fd, path = tempfile.mkstemp(suffix=suffix, prefix=prefix)\n    try:\n        # Close file descriptor but keep the file\n        os.close(fd)\n        yield path\n    finally:\n        # Always clean up\n        try:\n            os.unlink(path)\n        except OSError:\n            pass\n\n# Usage\nwith secure_temp_file(suffix='.json') as temp_path:\n    Path(temp_path).write_text(json.dumps(data))\n    process_file(temp_path)\n    # File automatically deleted when done\n```\n\n### Temporary Directories\n\n```python\nimport tempfile\nimport shutil\n\n@contextlib.contextmanager\ndef secure_temp_dir():\n    \"\"\"Create secure temporary directory\"\"\"\n    temp_dir = tempfile.mkdtemp(prefix='workspace_')\n    try:\n        # Set restrictive permissions\n        os.chmod(temp_dir, 0o700)\n        yield temp_dir\n    finally:\n        # Recursive removal\n        shutil.rmtree(temp_dir, ignore_errors=True)\n```\n\n## File Permissions and Security\n\n### Checking Permissions\n\n```python\ndef check_file_permissions(filepath):\n    \"\"\"Check if file has secure permissions\"\"\"\n    filepath = Path(filepath).resolve()\n    stat = filepath.stat()\n    mode = stat.st_mode\n    \n    # Check for world-writable\n    if mode & 0o002:\n        raise PermissionError(\"File is world-writable\")\n    \n    # Check for group-writable (optional)\n    if mode & 0o020:\n        print(\"Warning: File is group-writable\")\n    \n    # Check ownership\n    if stat.st_uid != os.getuid():\n        raise PermissionError(\"File not owned by current user\")\n```\n\n### Setting Secure Permissions\n\n```python\ndef set_secure_permissions(filepath, is_executable=False):\n    \"\"\"Set secure file permissions\"\"\"\n    filepath = Path(filepath).resolve()\n    \n    if is_executable:\n        # Owner: rwx, Group: r-x, Other: r-x\n        mode = 0o755\n    else:\n        # Owner: rw-, Group: r--, Other: r--\n        mode = 0o644\n    \n    # For sensitive files, remove group/other access\n    if 'private' in str(filepath) or 'secret' in str(filepath):\n        mode = 0o600  # Owner only\n    \n    filepath.chmod(mode)\n```\n\n## Directory Traversal\n\n### Safe Directory Walking\n\n```python\ndef walk_directory_safely(root_path, max_depth=10):\n    \"\"\"Safely walk directory tree with depth limit\"\"\"\n    root_path = Path(root_path).resolve()\n    \n    for dirpath, dirnames, filenames in os.walk(root_path):\n        # Calculate depth\n        depth = len(Path(dirpath).relative_to(root_path).parts)\n        \n        if depth >= max_depth:\n            dirnames[:] = []  # Don't recurse deeper\n            continue\n        \n        # Skip hidden directories\n        dirnames[:] = [d for d in dirnames if not d.startswith('.')]\n        \n        for filename in filenames:\n            # Skip hidden files\n            if filename.startswith('.'):\n                continue\n            \n            filepath = Path(dirpath) / filename\n            yield filepath\n```\n\n### Finding Files Safely\n\n```python\nimport fnmatch\n\ndef find_files_safely(root_path, pattern, max_results=1000):\n    \"\"\"Find files matching pattern with limits\"\"\"\n    root_path = Path(root_path).resolve()\n    results = []\n    \n    for filepath in walk_directory_safely(root_path):\n        if fnmatch.fnmatch(filepath.name, pattern):\n            results.append(filepath)\n            \n            if len(results) >= max_results:\n                print(f\"Warning: Result limit ({max_results}) reached\")\n                break\n    \n    return results\n```\n\n## File Locking\n\n### Exclusive File Access\n\n```python\nimport fcntl\nimport errno\n\ndef exclusive_file_access(filepath, operation):\n    \"\"\"Perform operation with exclusive file access\"\"\"\n    filepath = Path(filepath).resolve()\n    \n    with open(filepath, 'r+b') as f:\n        try:\n            # Try to acquire exclusive lock (non-blocking)\n            fcntl.flock(f.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB)\n            \n            try:\n                # Perform operation\n                return operation(f)\n            finally:\n                # Always release lock\n                fcntl.flock(f.fileno(), fcntl.LOCK_UN)\n                \n        except IOError as e:\n            if e.errno in (errno.EACCES, errno.EAGAIN):\n                raise IOError(\"File is locked by another process\")\n            raise\n```\n\n## Monitoring File Changes\n\n### Safe File Watching\n\n```python\nimport time\nfrom pathlib import Path\n\ndef watch_file_safely(filepath, callback, interval=1.0):\n    \"\"\"Watch file for changes safely\"\"\"\n    filepath = Path(filepath).resolve()\n    \n    if not filepath.exists():\n        raise FileNotFoundError(f\"File not found: {filepath}\")\n    \n    last_mtime = filepath.stat().st_mtime\n    last_size = filepath.stat().st_size\n    \n    while True:\n        try:\n            current_stat = filepath.stat()\n            current_mtime = current_stat.st_mtime\n            current_size = current_stat.st_size\n            \n            # Check for changes\n            if current_mtime != last_mtime or current_size != last_size:\n                callback(filepath)\n                last_mtime = current_mtime\n                last_size = current_size\n            \n        except FileNotFoundError:\n            # File was deleted\n            callback(None)\n            break\n        except Exception as e:\n            print(f\"Error watching file: {e}\")\n        \n        time.sleep(interval)\n```\n\n## Cleanup and Resource Management\n\n### Ensuring Cleanup\n\n```python\nclass FileManager:\n    \"\"\"Manage file resources with guaranteed cleanup\"\"\"\n    \n    def __init__(self):\n        self.temp_files = []\n        self.open_files = []\n    \n    def create_temp_file(self, **kwargs):\n        \"\"\"Create temp file tracked for cleanup\"\"\"\n        fd, path = tempfile.mkstemp(**kwargs)\n        self.temp_files.append(path)\n        os.close(fd)\n        return path\n    \n    def open_file(self, filepath, mode='r'):\n        \"\"\"Open file tracked for cleanup\"\"\"\n        f = open(filepath, mode)\n        self.open_files.append(f)\n        return f\n    \n    def cleanup(self):\n        \"\"\"Clean up all resources\"\"\"\n        # Close all open files\n        for f in self.open_files:\n            try:\n                f.close()\n            except:\n                pass\n        \n        # Remove all temp files\n        for path in self.temp_files:\n            try:\n                os.unlink(path)\n            except:\n                pass\n    \n    def __enter__(self):\n        return self\n    \n    def __exit__(self, exc_type, exc_val, exc_tb):\n        self.cleanup()\n```\n\n## Best Practices Summary\n\n1. **Always validate and sanitize paths**\n   - Use `realpath` or `Path.resolve()`\n   - Check paths stay within allowed directories\n\n2. **Handle errors gracefully**\n   - Expect filesystem operations to fail\n   - Provide meaningful error messages\n\n3. **Use atomic operations**\n   - Write to temp file then rename\n   - Use file locking when needed\n\n4. **Set appropriate permissions**\n   - Avoid world-writable files\n   - Use restrictive permissions for sensitive data\n\n5. **Clean up resources**\n   - Close files when done\n   - Remove temporary files\n   - Use context managers\n\n6. **Implement limits**\n   - File size limits\n   - Directory depth limits  \n   - Result count limits\n\n7. **Be cautious with user input**\n   - Never use user input directly in paths\n   - Validate file types and content\n\n8. **Monitor and log operations**\n   - Log file access for security\n   - Monitor for unusual patterns\n\nRemember: Filesystem operations are privileged operations. Always assume they can fail and always validate inputs to prevent security vulnerabilities.",
  "metadata": {
    "created_at": "2024-01-01T00:00:00Z",
    "updated_at": "2024-01-01T00:00:00Z",
    "tags": ["filesystem", "security", "safety", "best-practices"],
    "is_builtin": false,
    "author": "Gemini CLI Manager Team"
  }
}